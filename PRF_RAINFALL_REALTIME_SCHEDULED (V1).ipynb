{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "kqtpe4pfvx3yghdtihdv",
   "authorId": "7463897734774",
   "authorName": "AKEENANTFCDOP1023",
   "authorEmail": "akeenan@texasfcs.com",
   "sessionId": "1c506be1-c116-4105-b742-bd0ba10a8c8b",
   "lastEditTime": 1771537292775
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "CELL_1_NETWORK_ACCESS"
   },
   "source": "-- ════════════════════════════════════════════════════════════════\n-- CELL 1: Network Access\n-- Safe to re-run daily — CREATE OR REPLACE is idempotent.\n-- ════════════════════════════════════════════════════════════════\n\nCREATE OR REPLACE NETWORK RULE noaa_cpc_rule\n    MODE = EGRESS\n    TYPE = HOST_PORT\n    VALUE_LIST = ('ftp.cpc.ncep.noaa.gov:443', 'ftp.cpc.ncep.noaa.gov:80');\n\nCREATE OR REPLACE NETWORK RULE rma_ftp_rule\n    MODE = EGRESS\n    TYPE = HOST_PORT\n    VALUE_LIST = ('pubfs-rma.fpac.usda.gov:443', 'pubfs-rma.fpac.usda.gov:80');\n\nCREATE OR REPLACE EXTERNAL ACCESS INTEGRATION noaa_cpc_access\n    ALLOWED_NETWORK_RULES = (noaa_cpc_rule, rma_ftp_rule)\n    ENABLED = TRUE;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "CELL_2_CREATE_TABLES"
   },
   "source": "-- ════════════════════════════════════════════════════════════════\n-- CELL 2: Create Tables\n-- Safe to re-run daily — IF NOT EXISTS.\n-- ════════════════════════════════════════════════════════════════\n\nCREATE TABLE IF NOT EXISTS PRF_RAINFALL_REALTIME (\n    observation_date    DATE            NOT NULL,\n    latitude            FLOAT           NOT NULL,\n    longitude           FLOAT           NOT NULL,\n    precip_mm           FLOAT,\n    precip_in           FLOAT,\n    gauge_count         INT,\n    file_type           VARCHAR(10),\n    ingested_at         TIMESTAMP_NTZ,\n    CONSTRAINT pk_prf_rain PRIMARY KEY (observation_date, latitude, longitude)\n);\n\nCREATE TABLE IF NOT EXISTS PRF_GRID_REFERENCE (\n    grid_id             INT             NOT NULL,\n    center_lat          FLOAT           NOT NULL,\n    center_lon          FLOAT           NOT NULL,\n    state_fips          VARCHAR(2),\n    county_fips         VARCHAR(3),\n    area_acres          FLOAT,\n    ingested_at         TIMESTAMP_NTZ,\n    CONSTRAINT pk_prf_grid PRIMARY KEY (grid_id)\n);",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c7822bb3-588e-43b7-b3b8-36233fdb8326",
   "metadata": {
    "language": "sql",
    "name": "Cell_3_Email_Integration"
   },
   "outputs": [],
   "source": "-- ════════════════════════════════════════════════════════════════\n-- CELL 3: Email Notification Integration\n-- Safe to re-run — CREATE OR REPLACE.\n-- ════════════════════════════════════════════════════════════════\n\nCREATE OR REPLACE NOTIFICATION INTEGRATION prf_email_alerts\n    TYPE = EMAIL\n    ENABLED = TRUE\n    ALLOWED_RECIPIENTS = ('akeenan@texasfcs.com');\n\nGRANT USAGE ON INTEGRATION prf_email_alerts TO ROLE ACCOUNTADMIN;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "167da338-e663-4c8c-85e7-be4cdfb1af65",
   "metadata": {
    "language": "sql",
    "name": "Cell_4_Grid_Reference_Ingestion"
   },
   "outputs": [],
   "source": "-- ════════════════════════════════════════════════════════════════\n-- CELL 4: Grid Reference — only loads if table is empty.\n-- First run: downloads shapefile, loads ~25K grids.\n-- Subsequent runs: skips in <1 second.\n-- ════════════════════════════════════════════════════════════════\n\nCREATE OR REPLACE PROCEDURE SP_LOAD_GRID_REFERENCE_IF_EMPTY()\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.11'\nPACKAGES = ('snowflake-snowpark-python', 'geopandas', 'requests', 'shapely')\nEXTERNAL_ACCESS_INTEGRATIONS = (noaa_cpc_access)\nHANDLER = 'run'\nAS\n$$\nimport requests\nimport zipfile\nimport io\nimport os\nimport tempfile\nimport geopandas as gpd\nfrom datetime import datetime\n\ndef run(session):\n    count = session.sql(\"SELECT COUNT(*) AS cnt FROM PRF_GRID_REFERENCE\").collect()\n    if count[0]['CNT'] > 0:\n        return f\"SKIPPED: PRF_GRID_REFERENCE already has {count[0]['CNT']} grids.\"\n\n    url = \"https://pubfs-rma.fpac.usda.gov/pub/Miscellaneous_Files/VI_RI_Data/rainfall_index_grids.zip\"\n    resp = requests.get(url, timeout=120)\n\n    tmpdir = tempfile.mkdtemp()\n    z = zipfile.ZipFile(io.BytesIO(resp.content))\n    z.extractall(tmpdir)\n\n    shp_path = None\n    for root, dirs, files in os.walk(tmpdir):\n        for f in files:\n            if f.endswith('.shp'):\n                shp_path = os.path.join(root, f)\n                break\n\n    gdf = gpd.read_file(shp_path)\n    if gdf.crs and gdf.crs.to_epsg() != 4326:\n        gdf = gdf.to_crs(epsg=4326)\n\n    gdf['center_lat'] = gdf.geometry.centroid.y.round(3)\n    gdf['center_lon'] = gdf.geometry.centroid.x.round(3)\n\n    grid_id_col = None\n    for candidate in ['GRIDID', 'Grid_ID', 'GRID_ID', 'gridid', 'ID']:\n        if candidate in gdf.columns:\n            grid_id_col = candidate\n            break\n\n    if grid_id_col is None:\n        return f\"ERROR: Can't find grid ID column. Columns: {gdf.columns.tolist()}\"\n\n    now_str = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n    rows = []\n    for _, row in gdf.iterrows():\n        rows.append((\n            int(row[grid_id_col]),\n            float(row['center_lat']),\n            float(row['center_lon']),\n            None, None, None, now_str\n        ))\n\n    df = session.create_dataframe(\n        rows,\n        schema=['GRID_ID', 'CENTER_LAT', 'CENTER_LON',\n                'STATE_FIPS', 'COUNTY_FIPS', 'AREA_ACRES', 'INGESTED_AT']\n    )\n    df.write.mode(\"append\").save_as_table(\"PRF_GRID_REFERENCE\")\n\n    new_count = session.sql(\"SELECT COUNT(*) AS cnt FROM PRF_GRID_REFERENCE\").collect()\n    return f\"LOADED: {new_count[0]['CNT']} grids into PRF_GRID_REFERENCE\"\n$$;\n\nCALL SP_LOAD_GRID_REFERENCE_IF_EMPTY();",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f375a7e7-f835-4f0a-b051-af0e635b44a5",
   "metadata": {
    "language": "sql",
    "name": "Cell_5_Automated_rainfall_ingestion"
   },
   "outputs": [],
   "source": "-- ════════════════════════════════════════════════════════════════\n-- CELL 5: Automated RT Rainfall Ingestion (UNIT FIX 2026-02-19)\n-- ════════════════════════════════════════════════════════════════\n\nCREATE OR REPLACE PROCEDURE SP_INGEST_RT_RAINFALL()\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.11'\nPACKAGES = ('snowflake-snowpark-python', 'requests', 'numpy')\nEXTERNAL_ACCESS_INTEGRATIONS = (noaa_cpc_access)\nHANDLER = 'run'\nAS\n$$\nimport requests\nimport numpy as np\nfrom datetime import datetime, timedelta\n\ndef run(session):\n    NROWS       = 120\n    NCOLS       = 300\n    LON_START   = -129.875\n    LAT_START   =   20.125\n    STEP        =    0.25\n    MISSING     = -999.0\n    MAX_BACKFILL = 30\n    BASE_URL    = \"https://ftp.cpc.ncep.noaa.gov/precip/CPC_UNI_PRCP/GAUGE_CONUS\"\n\n    result = session.sql(\n        \"SELECT COALESCE(MAX(observation_date), '1948-01-01'::DATE) AS max_date \"\n        \"FROM PRF_RAINFALL_REALTIME WHERE file_type = 'RT'\"\n    ).collect()\n\n    last_loaded = datetime.strptime(str(result[0]['MAX_DATE']), '%Y-%m-%d').date()\n    yesterday   = (datetime.utcnow() - timedelta(days=1)).date()\n\n    start_date = last_loaded + timedelta(days=1)\n    earliest   = yesterday - timedelta(days=MAX_BACKFILL)\n    if start_date < earliest:\n        start_date = earliest\n\n    candidates = []\n    d = start_date\n    while d <= yesterday:\n        candidates.append(d)\n        d += timedelta(days=1)\n\n    if not candidates:\n        return \"UP_TO_DATE|0|0|\" + str(last_loaded)\n\n    loaded_dates  = []\n    skipped_dates = []\n\n    for target_date in candidates:\n        date_str = target_date.strftime('%Y%m%d')\n        year_str = target_date.strftime('%Y')\n        url = BASE_URL + \"/RT/\" + year_str + \"/PRCP_CU_GAUGE_V1.0CONUS_0.25deg.lnx.\" + date_str + \".RT\"\n\n        try:\n            resp = requests.get(url, timeout=30)\n        except Exception:\n            skipped_dates.append(date_str)\n            continue\n\n        if resp.status_code == 404:\n            break\n        elif resp.status_code != 200:\n            skipped_dates.append(date_str)\n            continue\n\n        raw = resp.content\n        expected = NROWS * NCOLS * 4 * 2\n        if len(raw) != expected:\n            skipped_dates.append(date_str)\n            continue\n\n        data = np.frombuffer(raw, dtype='<f4')\n        precip_grid = data[:NROWS * NCOLS].reshape(NROWS, NCOLS)\n        gauge_grid  = data[NROWS * NCOLS:].reshape(NROWS, NCOLS)\n\n        rows = []\n        obs_date_str = target_date.strftime('%Y-%m-%d')\n        now_str = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n\n        for r in range(NROWS):\n            for c in range(NCOLS):\n                raw_val = float(precip_grid[r, c])\n                if raw_val <= MISSING:\n                    continue\n                lat = round(LAT_START + r * STEP, 3)\n                lon = round(LON_START + c * STEP, 3)\n\n                # ─── UNIT FIX (2026-02-19) ──────────────────────────\n                # NOAA CPC binary stores precipitation in TENTHS of mm\n                # (0.1 mm units), NOT full millimeters.\n                #   raw_val = 128.5  means 12.85 mm, NOT 128.5 mm\n                #   PRECIP_MM = raw_val / 10.0\n                #   PRECIP_IN = raw_val / 254.0  (0.1mm -> inches)\n                # Previously divided by 25.4, producing 10x inflation.\n                # ─────────────────────────────────────────────────────\n                pmm = round(raw_val / 10.0, 2)\n                pin = round(raw_val / 254.0, 4)\n                gc  = int(gauge_grid[r, c])\n                rows.append((obs_date_str, lat, lon, pmm, pin, gc, 'RT', now_str))\n\n        if not rows:\n            skipped_dates.append(date_str)\n            continue\n\n        df = session.create_dataframe(\n            rows,\n            schema=['OBSERVATION_DATE', 'LATITUDE', 'LONGITUDE',\n                    'PRECIP_MM', 'PRECIP_IN', 'GAUGE_COUNT',\n                    'FILE_TYPE', 'INGESTED_AT']\n        )\n\n        session.sql(\n            \"DELETE FROM PRF_RAINFALL_REALTIME \"\n            \"WHERE observation_date = '\" + obs_date_str + \"' AND file_type = 'RT'\"\n        ).collect()\n\n        df.write.mode(\"append\").save_as_table(\"PRF_RAINFALL_REALTIME\")\n        loaded_dates.append(date_str)\n\n    if loaded_dates:\n        stats = session.sql(\n            \"SELECT MAX(observation_date) AS max_date, \"\n            \"COUNT(DISTINCT observation_date) AS total_days, \"\n            \"COUNT(*) AS total_rows \"\n            \"FROM PRF_RAINFALL_REALTIME WHERE file_type = 'RT'\"\n        ).collect()\n        return (\n            \"LOADED|\" + str(len(loaded_dates)) + \"|\" + str(len(skipped_dates))\n            + \"|\" + loaded_dates[0] + \"|\" + loaded_dates[-1]\n            + \"|\" + str(stats[0]['MAX_DATE']) + \"|\" + str(stats[0]['TOTAL_DAYS']) + \"|\" + str(stats[0]['TOTAL_ROWS'])\n            + \"|\" + (\",\".join(skipped_dates) if skipped_dates else \"none\")\n        )\n    elif skipped_dates:\n        return \"ERRORS|0|\" + str(len(skipped_dates)) + \"|\" + \",\".join(skipped_dates)\n    else:\n        return \"UP_TO_DATE|0|0|\" + str(last_loaded)\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5acb046-f5b1-4752-9f11-5e480809b75d",
   "metadata": {
    "language": "sql",
    "name": "Cell_6_Email"
   },
   "outputs": [],
   "source": "-- ════════════════════════════════════════════════════════════════\n-- CELL 6: Email notification\n-- Calls ingest proc, parses result, sends email to akeenan.\n-- ════════════════════════════════════════════════════════════════\n\nCREATE OR REPLACE PROCEDURE SP_INGEST_AND_NOTIFY()\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.11'\nPACKAGES = ('snowflake-snowpark-python')\nHANDLER = 'run'\nAS\n$$\nfrom datetime import datetime\n\ndef run(session):\n    RECIPIENT = 'akeenan@texasfcs.com'\n    now = datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')\n\n    result = session.sql(\"CALL SP_INGEST_RT_RAINFALL()\").collect()\n    raw = str(result[0][0])\n    parts = raw.split('|')\n    status = parts[0]\n\n    if status == 'LOADED':\n        loaded_count  = parts[1]\n        skipped_count = parts[2]\n        first_date    = parts[3]\n        last_date     = parts[4]\n        max_date      = parts[5]\n        total_days    = parts[6]\n        total_rows    = parts[7]\n        skipped_list  = parts[8]\n\n        subject = f\"PRF Rain RT: {loaded_count} day(s) loaded thru {last_date}\"\n        body = (\n            f\"PRF Rainfall RT Ingestion -- {now}\\n\\n\"\n            f\"STATUS: NEW DATA LOADED\\n\\n\"\n            f\"Dates loaded: {loaded_count}\\n\"\n            f\"  Range: {first_date} to {last_date}\\n\\n\"\n            f\"Dates skipped: {skipped_count}\\n\"\n            f\"  {skipped_list}\\n\\n\"\n            f\"Table snapshot:\\n\"\n            f\"  Latest RT date: {max_date}\\n\"\n            f\"  Total RT days:  {total_days}\\n\"\n            f\"  Total RT rows:  {total_rows}\\n\"\n        )\n\n    elif status == 'ERRORS':\n        skipped_count = parts[2]\n        skipped_list  = parts[3]\n\n        subject = f\"PRF Rain RT: ERRORS -- {now}\"\n        body = (\n            f\"PRF Rainfall RT Ingestion -- {now}\\n\\n\"\n            f\"STATUS: ERRORS -- NO DATA LOADED\\n\\n\"\n            f\"No dates successfully loaded.\\n\"\n            f\"Dates with errors: {skipped_list}\\n\\n\"\n            f\"Please check the notebook logs.\\n\"\n        )\n\n    else:\n        last_loaded = parts[3]\n\n        subject = f\"PRF Rain RT: Up to date -- {last_loaded}\"\n        body = (\n            f\"PRF Rainfall RT Ingestion -- {now}\\n\\n\"\n            f\"STATUS: ALREADY UP TO DATE\\n\\n\"\n            f\"No new dates to load.\\n\"\n            f\"Last loaded RT date: {last_loaded}\\n\"\n            f\"NOAA typically publishes with a 1-2 day lag.\\n\"\n        )\n\n    # Escape single quotes in subject/body for SQL\n    safe_subject = subject.replace(\"'\", \"''\")\n    safe_body    = body.replace(\"'\", \"''\")\n\n    session.sql(f\"\"\"\n        CALL SYSTEM$SEND_EMAIL(\n            'prf_email_alerts',\n            '{RECIPIENT}',\n            '{safe_subject}',\n            '{safe_body}'\n        )\n    \"\"\").collect()\n\n    return f\"Email sent to {RECIPIENT}: {subject}\"\n$$;\n\nCALL SP_INGEST_AND_NOTIFY();",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "523bbbab-6bcd-4f76-b557-02ec74fb8435",
   "metadata": {
    "language": "sql",
    "name": "Cell_7_health_check"
   },
   "outputs": [],
   "source": "-- ════════════════════════════════════════════════════════════════\n-- CELL 7: Health check — latest 10 days loaded\n-- ════════════════════════════════════════════════════════════════\n\nSELECT\n    observation_date,\n    file_type,\n    COUNT(*)                        AS cell_count,\n    ROUND(AVG(precip_mm), 2)       AS avg_mm,\n    ROUND(MAX(precip_mm), 2)       AS max_mm,\n    ROUND(SUM(precip_mm), 0)       AS total_mm,\n    MIN(ingested_at)               AS loaded_at\nFROM PRF_RAINFALL_REALTIME\nGROUP BY observation_date, file_type\nORDER BY observation_date DESC\nLIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e4214c2-bb74-4899-a4aa-a96c085ec417",
   "metadata": {
    "language": "sql",
    "name": "APPENDIX_RANGEBOUND_VERSION"
   },
   "outputs": [],
   "source": "-- ════════════════════════════════════════════════════════════════\n-- CELL 8: Range-bound RT Reload\n-- Usage: CALL SP_RELOAD_RT_RAINFALL('20260101', '20260219');\n-- ════════════════════════════════════════════════════════════════\n\nCREATE OR REPLACE PROCEDURE SP_RELOAD_RT_RAINFALL(START_DATE VARCHAR, END_DATE VARCHAR)\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = '3.11'\nPACKAGES = ('snowflake-snowpark-python', 'requests', 'numpy')\nEXTERNAL_ACCESS_INTEGRATIONS = (noaa_cpc_access)\nHANDLER = 'run'\nAS\n$$\nimport requests\nimport numpy as np\nfrom datetime import datetime, timedelta\n\ndef run(session, start_date: str, end_date: str):\n    NROWS       = 120\n    NCOLS       = 300\n    LON_START   = -129.875\n    LAT_START   =   20.125\n    STEP        =    0.25\n    MISSING     = -999.0\n    BASE_URL    = \"https://ftp.cpc.ncep.noaa.gov/precip/CPC_UNI_PRCP/GAUGE_CONUS\"\n\n    current = datetime.strptime(start_date, '%Y%m%d').date()\n    end     = datetime.strptime(end_date,   '%Y%m%d').date()\n\n    loaded_dates  = []\n    skipped_dates = []\n\n    while current <= end:\n        date_str = current.strftime('%Y%m%d')\n        year_str = current.strftime('%Y')\n        url = BASE_URL + \"/RT/\" + year_str + \"/PRCP_CU_GAUGE_V1.0CONUS_0.25deg.lnx.\" + date_str + \".RT\"\n\n        try:\n            resp = requests.get(url, timeout=30)\n        except Exception:\n            skipped_dates.append(date_str)\n            current += timedelta(days=1)\n            continue\n\n        if resp.status_code != 200:\n            skipped_dates.append(date_str)\n            current += timedelta(days=1)\n            continue\n\n        raw = resp.content\n        expected = NROWS * NCOLS * 4 * 2\n        if len(raw) != expected:\n            skipped_dates.append(date_str)\n            current += timedelta(days=1)\n            continue\n\n        data = np.frombuffer(raw, dtype='<f4')\n        precip_grid = data[:NROWS * NCOLS].reshape(NROWS, NCOLS)\n        gauge_grid  = data[NROWS * NCOLS:].reshape(NROWS, NCOLS)\n\n        rows = []\n        obs_date_str = current.strftime('%Y-%m-%d')\n        now_str = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n\n        for r in range(NROWS):\n            for c in range(NCOLS):\n                raw_val = float(precip_grid[r, c])\n                if raw_val <= MISSING:\n                    continue\n                lat = round(LAT_START + r * STEP, 3)\n                lon = round(LON_START + c * STEP, 3)\n\n                # ─── UNIT FIX (2026-02-19) ──────────────────────────\n                # NOAA CPC binary: values in 0.1mm (tenths of mm)\n                # ─────────────────────────────────────────────────────\n                pmm = round(raw_val / 10.0, 2)\n                pin = round(raw_val / 254.0, 4)\n                gc  = int(gauge_grid[r, c])\n                rows.append((obs_date_str, lat, lon, pmm, pin, gc, 'RT', now_str))\n\n        if not rows:\n            skipped_dates.append(date_str)\n            current += timedelta(days=1)\n            continue\n\n        df = session.create_dataframe(\n            rows,\n            schema=['OBSERVATION_DATE', 'LATITUDE', 'LONGITUDE',\n                    'PRECIP_MM', 'PRECIP_IN', 'GAUGE_COUNT',\n                    'FILE_TYPE', 'INGESTED_AT']\n        )\n\n        session.sql(\n            \"DELETE FROM PRF_RAINFALL_REALTIME \"\n            \"WHERE observation_date = '\" + obs_date_str + \"' AND file_type = 'RT'\"\n        ).collect()\n\n        df.write.mode(\"append\").save_as_table(\"PRF_RAINFALL_REALTIME\")\n        loaded_dates.append(date_str)\n        current += timedelta(days=1)\n\n    loaded_str  = str(len(loaded_dates))\n    skipped_str = str(len(skipped_dates))\n\n    if loaded_dates:\n        return (\n            \"RELOAD_OK|\" + loaded_str + \" loaded|\" + skipped_str + \" skipped\"\n            + \"|\" + loaded_dates[0] + \" thru \" + loaded_dates[-1]\n            + \"|skipped: \" + (\",\".join(skipped_dates) if skipped_dates else \"none\")\n        )\n    else:\n        return \"RELOAD_FAIL|0 loaded|\" + skipped_str + \" skipped|\" + \",\".join(skipped_dates)\n$$;\n\n-- Run it for whatever range you need:\nCALL SP_RELOAD_RT_RAINFALL('20260101', '20260219');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b431e95e-4396-4068-bc28-37fcbeb906d7",
   "metadata": {
    "language": "sql",
    "name": "EMERGENCY_CHECK"
   },
   "outputs": [],
   "source": "SELECT \n    r.OBSERVATION_DATE,\n    COUNT(*) AS row_count,\n    SUM(r.PRECIP_IN) AS total_precip,\n    MIN(r.PRECIP_IN) AS single_day_value\nFROM CAPITAL_MARKETS_SANDBOX.PUBLIC.PRF_RAINFALL_REALTIME r\nJOIN CAPITAL_MARKETS_SANDBOX.PUBLIC.PRF_GRID_REFERENCE g\n  ON r.LATITUDE = g.CENTER_LAT\n  AND r.LONGITUDE = g.CENTER_LON\nWHERE g.GRIDCODE = 8830\n  AND r.OBSERVATION_DATE BETWEEN '2026-02-08' AND '2026-02-17'\nGROUP BY r.OBSERVATION_DATE\nORDER BY r.OBSERVATION_DATE;",
   "execution_count": null
  }
 ]
}